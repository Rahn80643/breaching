{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ebef44a",
   "metadata": {},
   "source": [
    "# Inverting Gradients - How easy is it to break privacy in federated learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a756fc5f",
   "metadata": {},
   "source": [
    "This notebook shows an example for a **small-batch image gradient inversion** as described in \"Inverting Gradients - How easy is it to break privacy in federated learning?\". The setting is a trained ResNet-18 and the federated learning algorithm is **fedAVG**.\n",
    "\n",
    "Paper URL: https://proceedings.neurips.cc/paper/2020/hash/c4ede56bbd98819ae6112b20ac6bf145-Abstract.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6366c2f3",
   "metadata": {},
   "source": [
    "This notebook can replicate the experiments in Fig.5 and Tab. 2 of this paper."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31823a2",
   "metadata": {},
   "source": [
    "#### Abstract\n",
    "The idea of federated learning is to collaboratively train a neural network on a server. Each user receives the current weights of the network and in turns sends parameter updates (gradients) based on local data. This protocol has been designed not only to train neural networks data-efficiently, but also to provide privacy benefits for users, as their input data remains on device and only parameter gradients are shared. But how secure is sharing parameter gradients? Previous attacks have provided a false sense of security, by succeeding only in contrived settings - even for a single image. However, by exploiting a magnitude-invariant loss along with optimization strategies based on adversarial attacks, we show that is is actually possible to faithfully reconstruct images at high resolution from the knowledge of their parameter gradients, and demonstrate that such a break of privacy is possible even for trained deep networks. We analyze the effects of architecture as well as parameters on the difficulty of reconstructing an input image and prove that any input to a fully connected layer can be reconstructed analytically independent of the remaining architecture. Finally we discuss settings encountered in practice and show that even averaging gradients over several iterations or several images does not protect the user's privacy in federated learning applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c7223c",
   "metadata": {},
   "source": [
    "### Startup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b850eabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import breaching\n",
    "except ModuleNotFoundError:\n",
    "    # You only really need this safety net if you want to run these notebooks directly in the examples directory\n",
    "    # Don't worry about this if you installed the package or moved the notebook to the main directory.\n",
    "    import os; os.chdir(\"..\")\n",
    "    import breaching\n",
    "    \n",
    "    \n",
    "import torch\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Redirects logs directly into the jupyter notebook\n",
    "import logging, sys\n",
    "logging.basicConfig(level=logging.INFO, handlers=[logging.StreamHandler(sys.stdout)], format='%(message)s')\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d5e214",
   "metadata": {},
   "source": [
    "### Initialize cfg object and system setup:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bd663b",
   "metadata": {},
   "source": [
    "This will load the full configuration object. This includes the configuration for the use case and threat model as `cfg.case` and the hyperparameters and implementation of the attack as `cfg.attack`. All parameters can be modified below, or overriden with `overrides=` as if they were cmd-line arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7dc3a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Investigating use case fedavg_small_scale with server type honest_but_curious.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'device': device(type='cuda', index=0), 'dtype': torch.float32}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg = breaching.get_config(overrides=[\"case=4_fedavg_small_scale\", \"case/data=LFWPeople\"])\n",
    "          \n",
    "device = torch.device(f'cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "torch.backends.cudnn.benchmark = cfg.case.impl.benchmark\n",
    "setup = dict(device=device, dtype=getattr(torch, cfg.case.impl.dtype))\n",
    "setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203c5fb1",
   "metadata": {},
   "source": [
    "### Modify config options here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0764ef",
   "metadata": {},
   "source": [
    "You can use `.attribute` access to modify any of these configurations for the attack, or the case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac118ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.case.data.partition=\"random\"\n",
    "cfg.case.user.user_idx = 1\n",
    "cfg.case.model='resnet18'\n",
    "\n",
    "cfg.case.user.provide_labels = True\n",
    "\n",
    "# These settings govern the total amount of user data and how it is used over multiple local update steps:\n",
    "cfg.case.user.num_data_points = 4\n",
    "cfg.case.user.num_local_updates = 4\n",
    "cfg.case.user.num_data_per_local_update_step = 2\n",
    "\n",
    "\n",
    "# Total variation regularization needs to be smaller on CIFAR-10:\n",
    "cfg.attack.regularization.total_variation.scale = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f64389",
   "metadata": {},
   "source": [
    "### Instantiate all parties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce37e668",
   "metadata": {},
   "source": [
    "The following lines generate \"server, \"user\" and \"attacker\" objects and print an overview of their configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3abd955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Model architecture resnet18 loaded with 11,220,645 parameters and 9,620 buffers.\n",
      "Overall this is a data ratio of      19:1 for target shape [4, 3, 224, 224] given that num_queries=1.\n",
      "User (of type UserMultiStep) with settings:\n",
      "    Number of data points: 4\n",
      "\n",
      "    Threat model:\n",
      "    User provides labels: True\n",
      "    User provides buffers: False\n",
      "    User provides number of data points: True\n",
      "\n",
      "    Data:\n",
      "    Dataset: LFWPeople\n",
      "    user: 1\n",
      "    \n",
      "        \n",
      "    Local FL Setup:\n",
      "        Number of local update steps: 4\n",
      "        Data per local update step: 2\n",
      "        Local learning rate: 0.001\n",
      "\n",
      "        Threat model:\n",
      "        Share these hyperparams to server: True\n",
      "\n",
      "        \n",
      "Server (of type HonestServer) with settings:\n",
      "    Threat model: Honest-but-curious\n",
      "    Number of planned queries: 1\n",
      "    Has external/public data: False\n",
      "\n",
      "    Model:\n",
      "        model specification: resnet18\n",
      "        model state: default\n",
      "        public buffers: True\n",
      "\n",
      "    Secrets: {}\n",
      "    \n",
      "Attacker (of type OptimizationBasedAttacker) with settings:\n",
      "    Hyperparameter Template: invertinggradients\n",
      "\n",
      "    Objective: Cosine Similarity with scale=1.0 and task reg=0.0\n",
      "    Regularizers: Total Variation, scale=0.001. p=1 q=1. \n",
      "    Augmentations: \n",
      "\n",
      "    Optimization Setup:\n",
      "        optimizer: adam\n",
      "        signed: hard\n",
      "        step_size: 0.1\n",
      "        boxed: True\n",
      "        max_iterations: 24\n",
      "        step_size_decay: step-lr\n",
      "        langevin_noise: 0.0\n",
      "        warmup: 0\n",
      "        grad_clip: None\n",
      "        callback: 100\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "user, server, model, loss_fn = breaching.cases.construct_case(cfg.case, setup)\n",
    "attacker = breaching.attacks.prepare_attack(server.model, server.loss, cfg.attack, setup)\n",
    "breaching.utils.overview(server, user, attacker)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548c0ad6",
   "metadata": {},
   "source": [
    "### Simulate an attacked FL protocol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2058bcc2",
   "metadata": {},
   "source": [
    "This exchange is a simulation of a single query in a federated learning protocol. The server sends out a `server_payload` and the user computes an update based on their private local data. This user update is `shared_data` and contains, for example, the parameter gradient of the model in the simplest case. `true_user_data` is also returned by `.compute_local_updates`, but of course not forwarded to the server or attacker and only used for (our) analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0dbd868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing user update on user 1 in model mode: eval.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/conda-bld/pytorch_1639180487213/work/aten/src/ATen/native/cuda/Loss.cu:247: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [0,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "/opt/conda/conda-bld/pytorch_1639180487213/work/aten/src/ATen/native/cuda/Loss.cu:247: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [1,0,0] Assertion `t >= 0 && t < n_classes` failed.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m server_payload \u001b[38;5;241m=\u001b[39m server\u001b[38;5;241m.\u001b[39mdistribute_payload()\n\u001b[0;32m----> 2\u001b[0m shared_data, true_user_data \u001b[38;5;241m=\u001b[39m \u001b[43muser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_local_updates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserver_payload\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/ryhuang/Data/federated_Learning/modifications/breaching/breaching/cases/users.py:378\u001b[0m, in \u001b[0;36mUserMultiStep.compute_local_updates\u001b[0;34m(self, server_payload)\u001b[0m\n\u001b[1;32m    376\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdata)\n\u001b[1;32m    377\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(outputs, data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m--> 378\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    380\u001b[0m grads_ref \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mparameters()]\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclip_value \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/breaching/lib/python3.9/site-packages/torch/_tensor.py:307\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    300\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    301\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    305\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    306\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 307\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/breaching/lib/python3.9/site-packages/torch/autograd/__init__.py:154\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retain_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    152\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m--> 154\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`"
     ]
    }
   ],
   "source": [
    "server_payload = server.distribute_payload()\n",
    "shared_data, true_user_data = user.compute_local_updates(server_payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c68628",
   "metadata": {},
   "outputs": [],
   "source": [
    "user.plot(true_user_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17255c5a",
   "metadata": {},
   "source": [
    "### Reconstruct user data:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798f4f44",
   "metadata": {},
   "source": [
    "Now we launch the attack, reconstructing user data based on only the `server_payload` and the `shared_data`. \n",
    "\n",
    "You can interrupt the computation early to see a partial solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a32fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_user_data, stats = attacker.reconstruct([server_payload], [shared_data], {}, dryrun=cfg.dryrun)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d746e854",
   "metadata": {},
   "source": [
    "Next we'll evaluate metrics, comparing the `reconstructed_user_data` to the `true_user_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f2685a",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = breaching.analysis.report(reconstructed_user_data, true_user_data, [server_payload], \n",
    "                                    server.model, order_batch=True, compute_full_iip=False, \n",
    "                                    cfg_case=cfg.case, setup=setup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9caa5d02",
   "metadata": {},
   "source": [
    "And finally, we also plot the reconstructed data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631f4a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "user.plot(reconstructed_user_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50889063",
   "metadata": {},
   "source": [
    "### Notes:\n",
    "* If labels are unknown, then a robust label recovery algorithm has to be used that does not count label repetitions due to shifts after local updates."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
